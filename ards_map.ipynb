{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import MarkerCluster\n",
    "import numpy as np\n",
    "from weight_optimization import calculate_weights\n",
    "from dataloader import load_data\n",
    "\n",
    "def preprocess_data(county_coordinates, smoking_data, copd_data, covid_data, sepsis_data, drowning_data, vaccination_data, flu_data, pneumonia_data):\n",
    "    state_abbreviations = {\n",
    "        'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "    }\n",
    "    merged_covid = pd.merge(covid_data, county_coordinates, left_on='fips', right_on='county_fips')\n",
    "    merged_covid['cases_per_population'] = merged_covid['cases'] / merged_covid['population']\n",
    "    merged_covid.dropna(subset=['lat', 'lng', 'cases_per_population'], inplace=True)\n",
    "    filtered_covid = merged_covid[(merged_covid['state_name'] != 'Alaska') & (merged_covid['state_name'] != 'Hawaii') & (merged_covid['lat'] < 60)]\n",
    "    min_covid, max_covid = filtered_covid['cases_per_population'].min(), filtered_covid['cases_per_population'].max()\n",
    "    normalized_covid = filtered_covid.copy()\n",
    "    normalized_covid['normalized_covid'] = (filtered_covid['cases_per_population'] - min_covid) / (max_covid - min_covid)\n",
    "\n",
    "    merged_smoking = pd.merge(county_coordinates, smoking_data, left_on='state_name', right_on='LocationDesc', how='left')\n",
    "    merged_smoking['Data_Value'].fillna(merged_smoking.groupby('state_name')['Data_Value'].transform('mean'), inplace=True)\n",
    "    filtered_smoking = merged_smoking[(merged_smoking['state_name'] != 'Alaska') & (merged_smoking['state_name'] != 'Hawaii') & (merged_smoking['lat'] < 60)]\n",
    "    min_smoking, max_smoking = filtered_smoking['Data_Value'].min(), filtered_smoking['Data_Value'].max()\n",
    "    normalized_smoking = filtered_smoking.copy()\n",
    "    normalized_smoking['normalized_smoking'] = (filtered_smoking['Data_Value'] - min_smoking) / (max_smoking - min_smoking)\n",
    "\n",
    "    merged_copd = pd.merge(copd_data, county_coordinates, left_on='LocationID', right_on='county_fips')\n",
    "    merged_copd.dropna(subset=['lat', 'lng', 'Percent_COPD'], inplace=True)\n",
    "    filtered_copd = merged_copd[(merged_copd['state_name'] != 'Alaska') & (merged_copd['state_name'] != 'Hawaii') & (merged_copd['lat'] < 60)]\n",
    "    min_copd, max_copd = 3.2, 15.5\n",
    "    normalized_copd = filtered_copd.copy()\n",
    "    normalized_copd['normalized_copd'] = (filtered_copd['Percent_COPD'] - min_copd) / (max_copd - min_copd)\n",
    "\n",
    "    sepsis_data['STATE_FULL'] = sepsis_data['STATE'].apply(lambda x: state_abbreviations.get(x))\n",
    "    merged_sepsis = pd.merge(county_coordinates, sepsis_data, left_on='state_name', right_on='STATE_FULL', how='left')\n",
    "    min_sepsis, max_sepsis = merged_sepsis['RATE'].min(), merged_sepsis['RATE'].max()\n",
    "    normalized_sepsis = merged_sepsis.copy()\n",
    "    normalized_sepsis['normalized_sepsis'] = (merged_sepsis['RATE'] - min_sepsis) / (max_sepsis - min_sepsis)\n",
    "\n",
    "    drowning_data['STATE_FULL'] = drowning_data['State'].apply(lambda x: state_abbreviations.get(x))\n",
    "    merged_drowning = pd.merge(county_coordinates, drowning_data, left_on='state_name', right_on='STATE_FULL', how='left')\n",
    "    min_drowning, max_drowning = merged_drowning['Dd'].min(), merged_drowning['Dd'].max()\n",
    "    normalized_drowning = merged_drowning.copy()\n",
    "    normalized_drowning['normalized_drowning'] = (merged_drowning['Dd'] - min_drowning) / (max_drowning - min_drowning)\n",
    "\n",
    "    merged_vaccination = pd.merge(county_coordinates, vaccination_data, left_on='state_name', right_on='Location', how='left')\n",
    "    min_vaccination, max_vaccination = merged_vaccination['Flu Vaccination Rate'].min(), merged_vaccination['Flu Vaccination Rate'].max()\n",
    "    normalized_vaccination = merged_vaccination.copy()\n",
    "    normalized_vaccination['normalized_vaccination'] = (merged_vaccination['Flu Vaccination Rate'] - min_vaccination) / (max_vaccination - min_vaccination)\n",
    "\n",
    "    merged_flu = pd.merge(county_coordinates, flu_data, left_on='state_name', right_on='STATENAME', how='left')\n",
    "    min_flu, max_flu = merged_flu['ACTIVITY_LEVEL'].min(), merged_flu['ACTIVITY_LEVEL'].max()\n",
    "    normalized_flu = merged_flu.copy()\n",
    "    normalized_flu['normalized_flu'] = (merged_flu['ACTIVITY_LEVEL'] - min_flu) / (max_flu - min_flu)\n",
    "\n",
    "    pneumonia_data['state_name'] = pneumonia_data['STATE'].apply(lambda x: state_abbreviations.get(x))\n",
    "    merged_pneumonia = pd.merge(county_coordinates, pneumonia_data, on='state_name', how='left')\n",
    "    min_pneumonia, max_pneumonia = merged_pneumonia['RATE'].min(), merged_pneumonia['RATE'].max()\n",
    "    normalized_pneumonia = merged_pneumonia.copy()\n",
    "    normalized_pneumonia['normalized_pneumonia'] = (merged_pneumonia['RATE'] - min_pneumonia) / (max_pneumonia - min_pneumonia)\n",
    "\n",
    "    combined_data = pd.merge(normalized_smoking, normalized_copd, on=['lat', 'lng', 'state_name'], suffixes=('_smoking', '_copd'))\n",
    "    combined_data = pd.merge(combined_data, normalized_covid, on=['lat', 'lng', 'state_name'])\n",
    "    combined_data = pd.merge(combined_data, normalized_sepsis[['county_fips', 'normalized_sepsis']], on='county_fips')\n",
    "    combined_data = pd.merge(combined_data, normalized_drowning[['county_fips', 'normalized_drowning']], on='county_fips')\n",
    "    combined_data = pd.merge(combined_data, normalized_vaccination[['county_fips', 'normalized_vaccination']], on='county_fips')\n",
    "    combined_data = pd.merge(combined_data, normalized_flu[['county_fips', 'normalized_flu']], on='county_fips')\n",
    "    combined_data = pd.merge(combined_data, normalized_pneumonia[['county_fips', 'normalized_pneumonia']], on='county_fips')\n",
    "    return combined_data\n",
    "\n",
    "def weights(combined_data):\n",
    "    #combined_data['combined_weighted_value'] = 0.1 * combined_data['normalized_smoking'] + 0.25 * combined_data['normalized_copd'] + 0.2 * combined_data['normalized_covid'] + 0.1 * combined_data['normalized_drowning'] + 0.15 * combined_data['normalized_sepsis'] + 0.05 * combined_data['normalized_vaccination'] + 0.05 * combined_data['normalized_flu'] + 0.1 * combined_data['normalized_pneumonia']\n",
    "    weights = calculate_weights('state_data_1.csv')\n",
    "\n",
    "    combined_data['combined_weighted_value'] = (\n",
    "        weights[0] * combined_data['normalized_smoking'] \n",
    "        + weights[1] * combined_data['normalized_copd']\n",
    "        + weights[2] * combined_data['normalized_covid']\n",
    "        + weights[3] * combined_data['normalized_drowning']\n",
    "        + weights[4] * combined_data['normalized_sepsis']\n",
    "        + weights[5] * combined_data['normalized_flu']\n",
    "        + weights[6] * combined_data['normalized_pneumonia']\n",
    "        + weights[7] * combined_data['normalized_vaccination']\n",
    "    )\n",
    "    combined_data.dropna(subset=['lat', 'lng', 'combined_weighted_value'], inplace=True)\n",
    "    heatmap_data = combined_data[['lat', 'lng', 'combined_weighted_value']].values.tolist()\n",
    "    df = pd.read_csv('ards_data/ARDS_centers.csv')\n",
    "    df = df.drop_duplicates(subset='Hospital Name')\n",
    "    locations = [(row['Latitude'], row['Longitude'], row['Hospital Name']) for _, row in df.iterrows()]\n",
    "    return combined_data, heatmap_data, locations\n",
    "    \n",
    "\n",
    "def create_usa_map():\n",
    "    usa_center_latitude = 40\n",
    "    usa_center_longitude = -98\n",
    "    usa_map = folium.Map(location=[usa_center_latitude, usa_center_longitude], zoom_start=4)\n",
    "    return usa_map\n",
    "\n",
    "def state_data(combined_data):\n",
    "    state_data = combined_data.groupby('state_name').mean().reset_index()\n",
    "    sd = state_data[['state_name','normalized_sepsis', 'normalized_drowning', 'normalized_vaccination', 'normalized_flu', 'normalized_pneumonia', 'normalized_smoking', 'normalized_copd', 'normalized_covid']]\n",
    "    vals = pd.read_csv('vals.csv')\n",
    "    sd.to_csv('state_data.csv', index=False)\n",
    "    sd['vals'] = df_vals['vals']\n",
    "    return sd\n",
    "\n",
    "\n",
    "def add_heatmap(usa_map, heatmap_data):\n",
    "    custom_gradient = {\n",
    "        0.0: '#0000FF', \n",
    "        0.7: '#3399FF',  \n",
    "        0.89: '#66FF66',  \n",
    "        0.94: '#FFFF00', \n",
    "        1.0: '#FF0000'    \n",
    "    }\n",
    "    HeatMap(heatmap_data, gradient=custom_gradient).add_to(usa_map)\n",
    "\n",
    "\n",
    "def add_marker_cluster(usa_map, locations):\n",
    "    marker_cluster = MarkerCluster().add_to(usa_map)\n",
    "    for lat, lon, name in locations:\n",
    "        folium.Marker(location=[lat, lon], popup=name).add_to(marker_cluster)\n",
    "\n",
    "\n",
    "def main():\n",
    "    county_coordinates, smoking_data, copd_data, covid_data, sepsis_data, drowning_data, vaccination_data, flu_data, pneumonia_data, ards_centers = load_data()\n",
    "    combined_data = preprocess_data(county_coordinates, smoking_data, copd_data, covid_data, sepsis_data, drowning_data, vaccination_data, flu_data, pneumonia_data)\n",
    "    data, heatmap_data, locations = weights(combined_data)\n",
    "    usa_map = create_usa_map()\n",
    "    add_heatmap(usa_map, heatmap_data)\n",
    "    add_marker_cluster(usa_map, locations)\n",
    "    usa_map.save('usa_map.html')\n",
    "    usa_map\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
  },
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
